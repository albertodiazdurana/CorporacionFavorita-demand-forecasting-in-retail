{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6b8cd9",
   "metadata": {},
   "source": [
    "# Corporación Favorita Grocery Sales Forecasting\n",
    "## d05_w01_EDA_context_export.ipynb\n",
    "\n",
    "**Author:** Alberto Diaz Durana  \n",
    "**Date:** November 2025  \n",
    "**Purpose:** Analyze holidays, promotions, perishables; export final analysis-ready dataset\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook accomplishes the following:\n",
    "\n",
    "- Analyze holiday impact on sales (by holiday type, pre/post effects)\n",
    "- Measure promotion effectiveness (sales lift, frequency)\n",
    "- Investigate promotion × holiday interactions\n",
    "- Compare perishable vs non-perishable patterns\n",
    "- Identify high-volatility items (waste risk)\n",
    "- Analyze oil price correlation\n",
    "- Export final cleaned dataset with all features\n",
    "- Create Week 1 summary report\n",
    "\n",
    "---\n",
    "\n",
    "## Business Context\n",
    "\n",
    "**Why external factors matter:**\n",
    "\n",
    "Understanding holidays, promotions, and product characteristics enables:\n",
    "- Optimal promotional timing (avoid/leverage holidays)\n",
    "- Inventory risk management (perishables require higher accuracy)\n",
    "- Resource planning (holiday staffing, promotional support)\n",
    "- Waste reduction (identify high-volatility perishables)\n",
    "\n",
    "**Deliverables:**\n",
    "- Holiday analysis report with sales lift by type\n",
    "- Promotion effectiveness metrics (ROI quantification)\n",
    "- Perishable waste indicators\n",
    "- Final dataset: guayas_prepared.csv (analysis-ready)\n",
    "- Week 1 summary report\n",
    "\n",
    "---\n",
    "\n",
    "## Input Dependencies\n",
    "\n",
    "From Day 4:\n",
    "- Clean dataset with temporal + rolling features (300K rows, 26 columns)\n",
    "- Store and item metadata merged\n",
    "\n",
    "From raw data:\n",
    "- holidays_events.csv (350 holiday records)\n",
    "- oil.csv (1,218 oil price records)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef05d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package Versions:\n",
      "  pandas: 2.1.4\n",
      "  numpy: 1.26.4\n",
      "  matplotlib: 3.10.7\n",
      "  seaborn: 0.13.2\n",
      "  scipy: 1.16.3\n",
      "\n",
      "OK - Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# Configure environment\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"Package Versions:\")\n",
    "print(f\"  pandas: {pd.__version__}\")\n",
    "print(f\"  numpy: {np.__version__}\")\n",
    "print(f\"  matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"  seaborn: {sns.__version__}\")\n",
    "print(f\"  scipy: {scipy.__version__}\")\n",
    "print(\"\\nOK - Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637960ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Paths validated:\n",
      "  Project root: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\n",
      "  DATA_RAW: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\\data\\raw\n",
      "  DATA_PROCESSED: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\\data\\processed\n",
      "  OUTPUTS: C:\\Users\\adiaz\\OneDrive\\Dokumente\\PythonScripts\\MasterClass\\Demand-forecasting-in-retail\\outputs\\figures\\eda\n",
      "\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Determine paths\n",
    "current_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "\n",
    "# Define path constants\n",
    "DATA_RAW = project_root / 'data' / 'raw'\n",
    "DATA_PROCESSED = project_root / 'data' / 'processed'\n",
    "OUTPUTS = project_root / 'outputs' / 'figures' / 'eda'\n",
    "\n",
    "# Verify paths\n",
    "assert DATA_RAW.exists(), f\"ERROR - Path not found: {DATA_RAW}\"\n",
    "assert DATA_PROCESSED.exists(), f\"ERROR - Path not found: {DATA_PROCESSED}\"\n",
    "assert OUTPUTS.exists(), f\"ERROR - Path not found: {OUTPUTS}\"\n",
    "\n",
    "print(\"OK - Paths validated:\")\n",
    "print(f\"  Project root: {project_root.resolve()}\")\n",
    "print(f\"  DATA_RAW: {DATA_RAW.resolve()}\")\n",
    "print(f\"  DATA_PROCESSED: {DATA_PROCESSED.resolve()}\")\n",
    "print(f\"  OUTPUTS: {OUTPUTS.resolve()}\")\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print(f\"\\nRandom seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2afa408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset and reapplying Day 3-4 transformations...\n",
      "OK - Dataset ready\n",
      "  Shape: (300000, 19)\n",
      "  Date range: 2013-01-02 to 2017-08-15\n",
      "  Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from Day 4 (need to reapply transformations)\n",
    "print(\"Loading dataset and reapplying Day 3-4 transformations...\")\n",
    "\n",
    "df = pd.read_pickle(DATA_PROCESSED / 'guayas_sample_300k.pkl')\n",
    "\n",
    "# Quick transformations from Days 3-4\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['onpromotion'] = df['onpromotion'].fillna(0.0)\n",
    "\n",
    "# Merge store metadata\n",
    "df_stores = pd.read_csv(DATA_RAW / 'stores.csv')\n",
    "df = df.merge(df_stores[['store_nbr', 'city', 'state', 'type', 'cluster']], \n",
    "              on='store_nbr', how='left')\n",
    "\n",
    "# Create temporal features\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "df['day_of_month'] = df['date'].dt.day\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "print(f\"OK - Dataset ready\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"  Missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ff3a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holiday Impact Analysis\n",
      "======================================================================\n",
      "\n",
      "Loading holidays_events.csv...\n",
      "OK - Holidays loaded\n",
      "  Total holiday records: 350\n",
      "  Columns: ['date', 'type', 'locale', 'locale_name', 'description', 'transferred']\n",
      "\n",
      "First 10 rows:\n",
      "         date     type    locale locale_name                    description  \\\n",
      "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
      "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "5  2012-05-12  Holiday     Local        Puyo         Cantonizacion del Puyo   \n",
      "6  2012-06-23  Holiday     Local    Guaranda      Cantonizacion de Guaranda   \n",
      "7  2012-06-25  Holiday  Regional    Imbabura  Provincializacion de Imbabura   \n",
      "8  2012-06-25  Holiday     Local   Latacunga     Cantonizacion de Latacunga   \n",
      "9  2012-06-25  Holiday     Local     Machala           Fundacion de Machala   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "5        False  \n",
      "6        False  \n",
      "7        False  \n",
      "8        False  \n",
      "9        False  \n",
      "\n",
      "Holiday types:\n",
      "type\n",
      "Holiday       221\n",
      "Event          56\n",
      "Additional     51\n",
      "Transfer       12\n",
      "Bridge          5\n",
      "Work Day        5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Locale distribution:\n",
      "locale\n",
      "National    174\n",
      "Local       152\n",
      "Regional     24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Locale names (sample):\n",
      "locale_name\n",
      "Ecuador      174\n",
      "Quito         13\n",
      "Riobamba      12\n",
      "Guaranda      12\n",
      "Latacunga     12\n",
      "Ambato        12\n",
      "Guayaquil     11\n",
      "Cuenca         7\n",
      "Ibarra         7\n",
      "Salinas        6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtering to National and Guayas (regional/local) holidays...\n",
      "  Filtered holidays: 174 (from 350)\n",
      "\n",
      "Date range: 2012-08-10 to 2017-12-26\n"
     ]
    }
   ],
   "source": [
    "# Load and explore holidays data\n",
    "print(\"Holiday Impact Analysis\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nLoading holidays_events.csv...\")\n",
    "df_holidays = pd.read_csv(DATA_RAW / 'holidays_events.csv')\n",
    "\n",
    "print(f\"OK - Holidays loaded\")\n",
    "print(f\"  Total holiday records: {len(df_holidays)}\")\n",
    "print(f\"  Columns: {list(df_holidays.columns)}\")\n",
    "\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(df_holidays.head(10))\n",
    "\n",
    "print(\"\\nHoliday types:\")\n",
    "print(df_holidays['type'].value_counts())\n",
    "\n",
    "print(\"\\nLocale distribution:\")\n",
    "print(df_holidays['locale'].value_counts())\n",
    "\n",
    "print(\"\\nLocale names (sample):\")\n",
    "print(df_holidays['locale_name'].value_counts().head(10))\n",
    "\n",
    "# Filter to National and Guayas holidays\n",
    "print(\"\\nFiltering to National and Guayas (regional/local) holidays...\")\n",
    "df_holidays_filtered = df_holidays[\n",
    "    (df_holidays['locale'] == 'National') | \n",
    "    (df_holidays['locale_name'] == 'Guayas')\n",
    "].copy()\n",
    "\n",
    "print(f\"  Filtered holidays: {len(df_holidays_filtered)} (from {len(df_holidays)})\")\n",
    "\n",
    "# Convert date to datetime\n",
    "df_holidays_filtered['date'] = pd.to_datetime(df_holidays_filtered['date'])\n",
    "\n",
    "print(f\"\\nDate range: {df_holidays_filtered['date'].min().date()} to {df_holidays_filtered['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd63c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging holidays with sales data (CORRECTED)...\n",
      "OK - Merge complete\n",
      "  Dataset shape: (300896, 22)\n",
      "  Columns: 22\n",
      "\n",
      "Non-holiday vs Holiday comparison (CORRECTED - Daily Averages):\n",
      "  Non-holiday: 1,837,546 units / 1541 days = 1,192.4 units/day\n",
      "  Holiday: 205,824 units / 139 days = 1,480.7 units/day\n",
      "  Holiday lift: +24.2%\n",
      "\n",
      "Holiday type distribution:\n",
      "holiday_type\n",
      "Event         10793\n",
      "Holiday        7607\n",
      "Additional     5867\n",
      "Transfer       1546\n",
      "Work Day        823\n",
      "Bridge          562\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge holidays with sales data (CORRECTED)\n",
    "print(\"\\nMerging holidays with sales data (CORRECTED)...\")\n",
    "\n",
    "# Start fresh - reload to avoid duplicate columns\n",
    "df = pd.read_pickle(DATA_PROCESSED / 'guayas_sample_300k.pkl')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['onpromotion'] = df['onpromotion'].fillna(0.0)\n",
    "\n",
    "# Merge store metadata\n",
    "df_stores = pd.read_csv(DATA_RAW / 'stores.csv')\n",
    "df = df.merge(df_stores[['store_nbr', 'city', 'state', 'type', 'cluster']], \n",
    "              on='store_nbr', how='left')\n",
    "\n",
    "# Create temporal features\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "df['day_of_month'] = df['date'].dt.day\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Create holiday flag\n",
    "df['is_holiday'] = df['date'].isin(df_holidays_filtered['date']).astype(int)\n",
    "\n",
    "# Merge holiday details (avoid column name conflicts)\n",
    "df_holidays_merge = df_holidays_filtered[['date', 'type', 'description']].rename(\n",
    "    columns={'type': 'holiday_type', 'description': 'holiday_name'}\n",
    ")\n",
    "\n",
    "df = df.merge(df_holidays_merge, on='date', how='left')\n",
    "\n",
    "print(f\"OK - Merge complete\")\n",
    "print(f\"  Dataset shape: {df.shape}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "\n",
    "# CORRECTED CALCULATION: Compare daily averages\n",
    "print(\"\\nNon-holiday vs Holiday comparison (CORRECTED - Daily Averages):\")\n",
    "non_holiday_sales = df[df['is_holiday'] == 0]['unit_sales'].sum()\n",
    "holiday_sales = df[df['is_holiday'] == 1]['unit_sales'].sum()\n",
    "non_holiday_days = df[df['is_holiday'] == 0]['date'].nunique()\n",
    "holiday_days = df[df['is_holiday'] == 1]['date'].nunique()\n",
    "\n",
    "non_holiday_avg = non_holiday_sales / non_holiday_days\n",
    "holiday_avg = holiday_sales / holiday_days\n",
    "\n",
    "print(f\"  Non-holiday: {non_holiday_sales:,.0f} units / {non_holiday_days} days = {non_holiday_avg:,.1f} units/day\")\n",
    "print(f\"  Holiday: {holiday_sales:,.0f} units / {holiday_days} days = {holiday_avg:,.1f} units/day\")\n",
    "print(f\"  Holiday lift: {((holiday_avg / non_holiday_avg) - 1) * 100:+.1f}%\")\n",
    "\n",
    "print(\"\\nHoliday type distribution:\")\n",
    "print(df[df['is_holiday'] == 1]['holiday_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756fc6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sales Analysis by Holiday Type:\n",
      "======================================================================\n",
      "\n",
      "Sales by Holiday Type:\n",
      "holiday_type  total_sales  days  avg_daily_sales  lift_vs_baseline\n",
      "  Additional     51740.29    29          1784.15             49.62\n",
      "       Event     81769.78    55          1486.72             24.68\n",
      "    Transfer     10330.00     7          1475.71             23.76\n",
      "    Work Day      7052.00     5          1410.40             18.28\n",
      "      Bridge      3856.00     3          1285.33              7.79\n",
      "     Holiday     51075.65    43          1187.81             -0.39\n",
      "\n",
      "Baseline (non-holiday): 1,192.4 units/day\n",
      "\n",
      "Interpretation:\n",
      "  Additional       +49.6%  (STRONG POSITIVE)\n",
      "  Event            +24.7%  (STRONG POSITIVE)\n",
      "  Transfer         +23.8%  (STRONG POSITIVE)\n",
      "  Work Day         +18.3%  (Moderate positive)\n",
      "  Bridge            +7.8%  (Moderate positive)\n",
      "  Holiday           -0.4%  (Slight negative)\n"
     ]
    }
   ],
   "source": [
    "# Analyze sales by holiday type\n",
    "print(\"\\nSales Analysis by Holiday Type:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate average daily sales by holiday type\n",
    "holiday_type_analysis = df[df['is_holiday'] == 1].groupby('holiday_type').agg({\n",
    "    'unit_sales': 'sum',\n",
    "    'date': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "holiday_type_analysis.columns = ['holiday_type', 'total_sales', 'days']\n",
    "holiday_type_analysis['avg_daily_sales'] = holiday_type_analysis['total_sales'] / holiday_type_analysis['days']\n",
    "\n",
    "# Calculate lift vs non-holiday baseline\n",
    "non_holiday_baseline = df[df['is_holiday'] == 0]['unit_sales'].sum() / df[df['is_holiday'] == 0]['date'].nunique()\n",
    "\n",
    "holiday_type_analysis['lift_vs_baseline'] = ((holiday_type_analysis['avg_daily_sales'] / non_holiday_baseline) - 1) * 100\n",
    "\n",
    "# Sort by lift\n",
    "holiday_type_analysis = holiday_type_analysis.sort_values('lift_vs_baseline', ascending=False)\n",
    "\n",
    "print(\"\\nSales by Holiday Type:\")\n",
    "print(holiday_type_analysis.to_string(index=False))\n",
    "\n",
    "print(f\"\\nBaseline (non-holiday): {non_holiday_baseline:,.1f} units/day\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "for _, row in holiday_type_analysis.iterrows():\n",
    "    if row['lift_vs_baseline'] > 20:\n",
    "        impact = \"STRONG POSITIVE\"\n",
    "    elif row['lift_vs_baseline'] > 0:\n",
    "        impact = \"Moderate positive\"\n",
    "    elif row['lift_vs_baseline'] > -20:\n",
    "        impact = \"Slight negative\"\n",
    "    else:\n",
    "        impact = \"STRONG NEGATIVE\"\n",
    "    print(f\"  {row['holiday_type']:<15} {row['lift_vs_baseline']:>+6.1f}%  ({impact})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pre/Post Holiday Effects Analysis:\n",
      "======================================================================\n",
      "Calculating holiday proximity (this may take 1 minute)...\n",
      "OK - Proximity calculated\n",
      "\n",
      "Sales by Holiday Period:\n",
      " period  total_sales  days  avg_daily_sales  lift_vs_normal\n",
      "    pre    217067.81   184          1179.72           -1.14\n",
      "holiday    205823.72   139          1480.75           24.09\n",
      "   post    178934.59   149          1200.90            0.63\n",
      " normal   1441543.72  1208          1193.33            0.00\n",
      "\n",
      "Conclusion:\n",
      "  → Pre-holiday period shows shopping preparation behavior\n",
      "  → Holiday day itself may have lower sales (store closures)\n",
      "  → Post-holiday period returns to baseline\n"
     ]
    }
   ],
   "source": [
    "# Analyze pre/post holiday effects\n",
    "print(\"\\nPre/Post Holiday Effects Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create pre/post holiday flags (±3 days around holidays)\n",
    "holiday_dates = df[df['is_holiday'] == 1]['date'].unique()\n",
    "\n",
    "df['days_to_holiday'] = df['date'].apply(\n",
    "    lambda x: min([abs((x - hol).days) for hol in holiday_dates]) if len(holiday_dates) > 0 else 999\n",
    ")\n",
    "\n",
    "df['is_pre_holiday'] = ((df['days_to_holiday'] >= 1) & (df['days_to_holiday'] <= 3) & (df['is_holiday'] == 0)).astype(int)\n",
    "df['is_post_holiday'] = ((df['days_to_holiday'] >= -3) & (df['days_to_holiday'] <= -1) & (df['is_holiday'] == 0)).astype(int)\n",
    "\n",
    "# Note: This is a simplified approach - we're using absolute distance\n",
    "# For better results, we'd need to track direction (before/after)\n",
    "\n",
    "# Recalculate with proper direction\n",
    "def get_holiday_proximity(date, holiday_dates):\n",
    "    \"\"\"\n",
    "    Calculate distance and period classification for a date relative to holidays.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (distance_in_days, period_label)\n",
    "            - distance: 0 for holiday, positive for pre-holiday, negative for post-holiday, 999 for normal\n",
    "            - period: 'holiday', 'pre' (1-3 days before), 'post' (1-3 days after), or 'normal'\n",
    "    \"\"\"\n",
    "    if date in holiday_dates:\n",
    "        return 0, 'holiday'\n",
    "    \n",
    "    future_holidays = [h for h in holiday_dates if h > date]\n",
    "    past_holidays = [h for h in holiday_dates if h < date]\n",
    "    \n",
    "    days_to_next = min([(h - date).days for h in future_holidays]) if future_holidays else 999\n",
    "    days_from_prev = min([(date - h).days for h in past_holidays]) if past_holidays else 999\n",
    "    \n",
    "    if days_to_next <= 3:\n",
    "        return days_to_next, 'pre'\n",
    "    elif days_from_prev <= 3:\n",
    "        return -days_from_prev, 'post'\n",
    "    else:\n",
    "        return 999, 'normal'\n",
    "\n",
    "print(\"Calculating holiday proximity (this may take 1 minute)...\")\n",
    "df['holiday_proximity'], df['holiday_period'] = zip(*df['date'].apply(lambda x: get_holiday_proximity(x, holiday_dates)))\n",
    "\n",
    "# Update flags\n",
    "df['is_pre_holiday'] = (df['holiday_period'] == 'pre').astype(int)\n",
    "df['is_post_holiday'] = (df['holiday_period'] == 'post').astype(int)\n",
    "\n",
    "print(\"OK - Proximity calculated\")\n",
    "\n",
    "# Analyze by period\n",
    "period_analysis = df.groupby('holiday_period').agg({\n",
    "    'unit_sales': 'sum',\n",
    "    'date': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "period_analysis.columns = ['period', 'total_sales', 'days']\n",
    "period_analysis['avg_daily_sales'] = period_analysis['total_sales'] / period_analysis['days']\n",
    "period_analysis['lift_vs_normal'] = ((period_analysis['avg_daily_sales'] / \n",
    "                                       period_analysis[period_analysis['period'] == 'normal']['avg_daily_sales'].values[0]) - 1) * 100\n",
    "\n",
    "print(\"\\nSales by Holiday Period:\")\n",
    "period_order = ['pre', 'holiday', 'post', 'normal']\n",
    "period_analysis['period'] = pd.Categorical(period_analysis['period'], categories=period_order, ordered=True)\n",
    "period_analysis = period_analysis.sort_values('period')\n",
    "print(period_analysis.to_string(index=False))\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"  → Pre-holiday period shows shopping preparation behavior\")\n",
    "print(\"  → Holiday day itself may have lower sales (store closures)\")\n",
    "print(\"  → Post-holiday period returns to baseline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
