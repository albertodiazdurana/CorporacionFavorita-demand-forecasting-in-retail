{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e37aba2",
   "metadata": {},
   "source": [
    "# FULL_02: Train Final Models (Production Pipeline)\n",
    "\n",
    "**Purpose:** Train XGBoost and LSTM on full Guayas dataset, compare performance at scale  \n",
    "**Input:** `data/processed/full_featured_data.pkl` (4.8M rows, 33 features)  \n",
    "**Output:** Production artifacts for best model\n",
    "\n",
    "**Key Decisions Applied:**\n",
    "- DEC-013: 7-day train/test gap\n",
    "- DEC-014: 33 features\n",
    "- DEC-016: Q4 2013 + Q1 2014 training (temporal consistency)\n",
    "\n",
    "**Week 3 Baseline (300K sample):**\n",
    "- XGBoost Tuned: RMSE 6.4860\n",
    "- LSTM: RMSE 6.2552\n",
    "\n",
    "**Metrics:** RMSE, MAE, MAPE (non-zero), Bias\n",
    "\n",
    "**Environment:** WSL2 Ubuntu 22.04, Python 3.11, TensorFlow 2.20.0 (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335b0434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:33:40.345880: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Setup:\n",
      "  TensorFlow version: 2.20.0\n",
      "  GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "  XGBoost version: 3.1.2\n",
      "  MLflow version: 3.6.0\n",
      "\n",
      "Paths:\n",
      "  Data: /home/berto/Demand-forecasting-in-retail/data/processed\n",
      "  Artifacts: /home/berto/Demand-forecasting-in-retail/artifacts\n",
      "  Outputs: /home/berto/Demand-forecasting-in-retail/outputs/figures/full_pipeline\n"
     ]
    }
   ],
   "source": [
    "### Section 1: Environment Setup\n",
    "# Source: w03_d01_MODEL_baseline.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.keras\n",
    "\n",
    "# Path configuration\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_PROCESSED = PROJECT_ROOT / 'data' / 'processed'\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / 'artifacts'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'outputs' / 'figures' / 'full_pipeline'\n",
    "\n",
    "# Create output directories\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check GPU\n",
    "print(\"Environment Setup:\")\n",
    "print(f\"  TensorFlow version: {tf.__version__}\")\n",
    "print(f\"  GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"  XGBoost version: {xgb.__version__}\")\n",
    "print(f\"  MLflow version: {mlflow.__version__}\")\n",
    "print(f\"\\nPaths:\")\n",
    "print(f\"  Data: {DATA_PROCESSED}\")\n",
    "print(f\"  Artifacts: {ARTIFACTS_DIR}\")\n",
    "print(f\"  Outputs: {OUTPUTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9a9c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full featured data...\n",
      "\n",
      "Dataset loaded:\n",
      "  Shape: (4801160, 42)\n",
      "  Memory: 2578.5 MB\n",
      "  Load time: 2.7 seconds\n",
      "  Date range: 2013-10-01 to 2014-03-31\n",
      "\n",
      "Feature configuration:\n",
      "  Features: 33\n",
      "  Target: unit_sales\n"
     ]
    }
   ],
   "source": [
    "### Section 2: Load Data\n",
    "# Source: FULL_01 output\n",
    "\n",
    "print(\"Loading full featured data...\")\n",
    "start_time = time.time()\n",
    "\n",
    "df = pd.read_pickle(DATA_PROCESSED / 'full_featured_data.pkl')\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nDataset loaded:\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\n",
    "print(f\"  Load time: {load_time:.1f} seconds\")\n",
    "print(f\"  Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "\n",
    "# Define 33 features per DEC-014\n",
    "FEATURE_COLUMNS = [\n",
    "    # Temporal (8)\n",
    "    'unit_sales_lag1', 'unit_sales_lag7', 'unit_sales_lag14', 'unit_sales_lag30',\n",
    "    'unit_sales_7d_avg', 'unit_sales_14d_avg', 'unit_sales_30d_avg',\n",
    "    'unit_sales_lag1_7d_corr',\n",
    "    \n",
    "    # Calendar (7)\n",
    "    'year', 'month', 'day', 'dayofweek', 'dayofyear', 'weekofyear', 'quarter',\n",
    "    \n",
    "    # Holiday (4)\n",
    "    'holiday_proximity', 'is_holiday', 'holiday_period', 'days_to_next_holiday',\n",
    "    \n",
    "    # Promotion (2)\n",
    "    'onpromotion', 'promo_item_interaction',\n",
    "    \n",
    "    # Store/Item (7)\n",
    "    'cluster', 'store_avg_sales', 'item_avg_sales', 'item_store_avg',\n",
    "    'cluster_avg_sales', 'family_avg_sales', 'city_avg_sales',\n",
    "    \n",
    "    # Derived (5)\n",
    "    'perishable', 'weekend', 'month_start', 'month_end', 'is_payday'\n",
    "]\n",
    "\n",
    "TARGET = 'unit_sales'\n",
    "\n",
    "print(f\"\\nFeature configuration:\")\n",
    "print(f\"  Features: {len(FEATURE_COLUMNS)}\")\n",
    "print(f\"  Target: {TARGET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb0a2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split (DEC-016 + DEC-013):\n",
      "--------------------------------------------------\n",
      "  Training: 2013-10-01 to 2014-02-21\n",
      "  Gap:      2014-02-22 to 2014-02-28 (7 days)\n",
      "  Test:     2014-03-01 to 2014-03-31\n",
      "\n",
      "Split results:\n",
      "  Training rows: 3,798,720\n",
      "  Test rows: 817,780\n",
      "  Gap rows excluded: 184,660\n",
      "\n",
      "Training period:\n",
      "  Days: 144\n",
      "  Stores: 10\n",
      "  Items: 2638\n",
      "\n",
      "Test period:\n",
      "  Days: 31\n",
      "  Stores: 10\n",
      "  Items: 2638\n"
     ]
    }
   ],
   "source": [
    "### Section 3: Train/Test Split\n",
    "# DEC-016: Q4 2013 + Q1 2014 training (temporal consistency)\n",
    "# DEC-013: 7-day gap between train end and test start\n",
    "\n",
    "# Define date boundaries\n",
    "TRAIN_START = '2013-10-01'\n",
    "TRAIN_END = '2014-02-21'\n",
    "GAP_START = '2014-02-22'\n",
    "GAP_END = '2014-02-28'\n",
    "TEST_START = '2014-03-01'\n",
    "TEST_END = '2014-03-31'\n",
    "\n",
    "print(\"Data Split (DEC-016 + DEC-013):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Training: {TRAIN_START} to {TRAIN_END}\")\n",
    "print(f\"  Gap:      {GAP_START} to {GAP_END} (7 days)\")\n",
    "print(f\"  Test:     {TEST_START} to {TEST_END}\")\n",
    "\n",
    "# Apply splits\n",
    "train_mask = (df['date'] >= TRAIN_START) & (df['date'] <= TRAIN_END)\n",
    "test_mask = (df['date'] >= TEST_START) & (df['date'] <= TEST_END)\n",
    "\n",
    "df_train = df[train_mask].copy()\n",
    "df_test = df[test_mask].copy()\n",
    "\n",
    "print(f\"\\nSplit results:\")\n",
    "print(f\"  Training rows: {len(df_train):,}\")\n",
    "print(f\"  Test rows: {len(df_test):,}\")\n",
    "print(f\"  Gap rows excluded: {len(df[(df['date'] >= GAP_START) & (df['date'] <= GAP_END)]):,}\")\n",
    "\n",
    "print(f\"\\nTraining period:\")\n",
    "print(f\"  Days: {df_train['date'].nunique()}\")\n",
    "print(f\"  Stores: {df_train['store_nbr'].nunique()}\")\n",
    "print(f\"  Items: {df_train['item_nbr'].nunique()}\")\n",
    "\n",
    "print(f\"\\nTest period:\")\n",
    "print(f\"  Days: {df_test['date'].nunique()}\")\n",
    "print(f\"  Stores: {df_test['store_nbr'].nunique()}\")\n",
    "print(f\"  Items: {df_test['item_nbr'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20c15a",
   "metadata": {},
   "source": [
    "The data split is working correctly:\n",
    "\n",
    "Training: 3.8M rows (144 days)\n",
    "Test: 818K rows (31 days)\n",
    "Gap: 185K rows excluded (7 days)\n",
    "\n",
    "This aligns with expectations from the handoff document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c849ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features and target...\n",
      "\n",
      "Feature data types:\n",
      "float64    15\n",
      "int64      11\n",
      "int32       6\n",
      "UInt32      1\n",
      "Name: count, dtype: int64\n",
      "  Converting weekofyear from UInt32 to float64\n",
      "float64    15\n",
      "int64      11\n",
      "int32       6\n",
      "UInt32      1\n",
      "Name: count, dtype: int64\n",
      "  Converting weekofyear from UInt32 to float64\n",
      "\n",
      "Shapes:\n",
      "  X_train: (3798720, 33), dtype: float32\n",
      "  y_train: (3798720,), dtype: float32\n",
      "  X_test: (817780, 33), dtype: float32\n",
      "  y_test: (817780,), dtype: float32\n",
      "\n",
      "NaN check:\n",
      "  X_train NaN: 0\n",
      "  X_test NaN: 0\n",
      "\n",
      "Target statistics:\n",
      "\n",
      "Shapes:\n",
      "  X_train: (3798720, 33), dtype: float32\n",
      "  y_train: (3798720,), dtype: float32\n",
      "  X_test: (817780, 33), dtype: float32\n",
      "  y_test: (817780,), dtype: float32\n",
      "\n",
      "NaN check:\n",
      "  X_train NaN: 0\n",
      "  X_test NaN: 0\n",
      "\n",
      "Target statistics:\n",
      "  Train - mean: 2.75, std: 11.62, median: 0.00\n",
      "  Test  - mean: 3.74, std: 12.18, median: 0.00\n",
      "\n",
      "Non-zero sales:\n",
      "  Train: 1,388,533 (36.6%)\n",
      "  Test: 375,806 (46.0%)\n",
      "  Train - mean: 2.75, std: 11.62, median: 0.00\n",
      "  Test  - mean: 3.74, std: 12.18, median: 0.00\n",
      "\n",
      "Non-zero sales:\n",
      "  Train: 1,388,533 (36.6%)\n",
      "  Test: 375,806 (46.0%)\n"
     ]
    }
   ],
   "source": [
    "### Section 4: Prepare Features and Target\n",
    "# Source: w03_d04_MODEL_lstm.ipynb\n",
    "\n",
    "print(\"Preparing features and target...\")\n",
    "\n",
    "# Check and fix data types (handle UInt32 from weekofyear)\n",
    "print(\"\\nFeature data types:\")\n",
    "print(df_train[FEATURE_COLUMNS].dtypes.value_counts())\n",
    "\n",
    "# Convert all features to standard float64 to avoid UInt32/nullable type issues\n",
    "for col in FEATURE_COLUMNS:\n",
    "    if df_train[col].dtype.name.startswith('UInt') or df_train[col].dtype.name.startswith('Int'):\n",
    "        print(f\"  Converting {col} from {df_train[col].dtype} to float64\")\n",
    "        df_train[col] = df_train[col].astype('float64')\n",
    "        df_test[col] = df_test[col].astype('float64')\n",
    "\n",
    "# Extract features and target\n",
    "X_train = df_train[FEATURE_COLUMNS].values.astype(np.float32)\n",
    "y_train = df_train[TARGET].values.astype(np.float32)\n",
    "X_test = df_test[FEATURE_COLUMNS].values.astype(np.float32)\n",
    "y_test = df_test[TARGET].values.astype(np.float32)\n",
    "\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  X_train: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"  y_train: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"  X_test: {X_test.shape}, dtype: {X_test.dtype}\")\n",
    "print(f\"  y_test: {y_test.shape}, dtype: {y_test.dtype}\")\n",
    "\n",
    "# Check for any remaining NaN\n",
    "train_nan = np.isnan(X_train).sum()\n",
    "test_nan = np.isnan(X_test).sum()\n",
    "print(f\"\\nNaN check:\")\n",
    "print(f\"  X_train NaN: {train_nan}\")\n",
    "print(f\"  X_test NaN: {test_nan}\")\n",
    "\n",
    "# Target statistics\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"  Train - mean: {y_train.mean():.2f}, std: {y_train.std():.2f}, median: {np.median(y_train):.2f}\")\n",
    "print(f\"  Test  - mean: {y_test.mean():.2f}, std: {y_test.std():.2f}, median: {np.median(y_test):.2f}\")\n",
    "\n",
    "# Non-zero counts (for MAPE calculation later)\n",
    "train_nonzero = (y_train > 0).sum()\n",
    "test_nonzero = (y_test > 0).sum()\n",
    "print(f\"\\nNon-zero sales:\")\n",
    "print(f\"  Train: {train_nonzero:,} ({train_nonzero/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Test: {test_nonzero:,} ({test_nonzero/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf9fe4",
   "metadata": {},
   "source": [
    "3.8M training, 818K test\n",
    "No NaN\n",
    "36.6% non-zero in train, 46.0% non-zero in test\n",
    "Using float32 for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17146908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics function defined: RMSE, MAE, Bias, MAPE (non-zero)\n"
     ]
    }
   ],
   "source": [
    "### Section 5: Define Evaluation Metrics\n",
    "# RMSE, MAE, MAPE (non-zero), Bias\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate all evaluation metrics.\"\"\"\n",
    "    # Primary metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    bias = np.mean(y_pred - y_true)\n",
    "    \n",
    "    # MAPE on non-zero only (avoid division by zero)\n",
    "    mask = y_true > 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((y_pred[mask] - y_true[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'bias': bias,\n",
    "        'mape_nonzero': mape\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics, model_name):\n",
    "    \"\"\"Print metrics in formatted table.\"\"\"\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  RMSE:          {metrics['rmse']:.4f}\")\n",
    "    print(f\"  MAE:           {metrics['mae']:.4f}\")\n",
    "    print(f\"  Bias:          {metrics['bias']:.4f}\")\n",
    "    print(f\"  MAPE (non-zero): {metrics['mape_nonzero']:.2f}%\")\n",
    "\n",
    "print(\"Metrics function defined: RMSE, MAE, Bias, MAPE (non-zero)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5cea71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 13:53:08 INFO mlflow.tracking.fluent: Experiment with name 'full_pipeline_model_comparison' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Configuration:\n",
      "  Tracking URI: file:///home/berto/Demand-forecasting-in-retail/mlflow_results\n",
      "  Experiment: full_pipeline_model_comparison\n",
      "\n",
      "Runs to log:\n",
      "  1. xgboost_full_q4q1\n",
      "  2. lstm_full_q4q1\n"
     ]
    }
   ],
   "source": [
    "### Section 6: MLflow Setup\n",
    "# Source: w03_d02_MODEL_mlflow-features.ipynb\n",
    "\n",
    "# Set MLflow tracking\n",
    "MLFLOW_DIR = PROJECT_ROOT / 'mlflow_results'\n",
    "MLFLOW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(f\"file://{MLFLOW_DIR}\")\n",
    "mlflow.set_experiment(\"full_pipeline_model_comparison\")\n",
    "\n",
    "print(\"MLflow Configuration:\")\n",
    "print(f\"  Tracking URI: file://{MLFLOW_DIR}\")\n",
    "print(f\"  Experiment: full_pipeline_model_comparison\")\n",
    "print(f\"\\nRuns to log:\")\n",
    "print(f\"  1. xgboost_full_q4q1\")\n",
    "print(f\"  2. lstm_full_q4q1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
